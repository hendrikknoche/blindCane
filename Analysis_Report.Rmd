---
title: "Evaluating the detectionspace - statistical report"
author: "by Milo Marsfeldt Skovfoged, Alexander Schiller Rasmussen"
date: "18/5/2020"
output:
  word_document: default
  pdf_document: default
---

## Table of Contents
1. [Introduction](#introduction)
2. [Data information](#data-information)
3. [Predicition of course completion time](#predicition-of-course-completion-time)
4. [Collisions and Detections](#collisions-and-detections)
5. [Speed](#speed)
6. [Analysis reflection](#analysis-reflection)
7. [Analysis conclusion](#analysis-conclusion)

## Introduction

This is the statistical report associated with the paper "Evaluating the detection space" by Milo Marsfeldt Skovfoged & Alexander Schiller Rasmussen. The field of study lies in researching visually impaired/blind navigation through environments, to find an ideal Range of looking ahead and Field of Detection (FOD), for the most progressive travel-route, while avoiding collisions as much as possible.
This report gives an overview of what data was gathered and analysed, in regrads to different points of interrest.

```{r setup, include=FALSE,}
library(tidyverse)
library(readbulk)
library(lubridate)
library(ggplot2)
library(scales) 
library(magrittr)
library(knitr)

#GetData
load('data_all.rda')

#Data Grouped by Snario
daggByScen <- df %>% filter(Person_Speed<3)%>%group_by(testID,day,Scenario,FOD,Range)%>%summarize(avgSpeed=mean(Person_Speed),medianSpeed=median(Person_Speed),maxSpeed=max(Person_Speed),minSpeed=min(Person_Speed),objectDetected=sum(objDet,na.rm = TRUE),objectCollisions=sum(objColl,na.rm = TRUE),Time=max(Time_in_MS*1000))%>% arrange(testID)

#add Coloum with sum of total time spent 
daggByScen$totalTimeTraining<-round(cumsum(daggByScen$Time))

#add Coloum with total time spent for a given FOD with a given Range
daggByScen <- daggByScen%>%group_by(FOD,day,Range)%>%mutate(timeFDRtrain=round(cumsum(Time)))

#add Coloum with total time spent for a given FOD
daggByScen <- daggByScen%>%group_by(FOD,day)%>%mutate(timeFDtrain=round(cumsum(Time)))

#add Coloum with total time spent for a given Day
daggByScen <- daggByScen%>%group_by(day)%>%mutate(timeDtrain=round(cumsum(Time)))
daggByCol <- df %>% filter(Person_Speed<3)%>%group_by(testID,day,Scenario,FOD,Range,objColl)%>%summarize(avgSpeed=mean(Person_Speed),medianSpeed=median(Person_Speed),maxSpeed=max(Person_Speed),minSpeed=min(Person_Speed),objectDetected=sum(objDet,na.rm = TRUE),objectCollisions=sum(objColl,na.rm = TRUE),Time=max(Time_in_MS*1000))%>% arrange(testID)


#Model equation
model_equation <- function(model, ...) {
  format_args <- list(...)
  
  model_coeff <- model$coefficients
  format_args$x <- abs(model$coefficients)
  model_coeff_sign <- sign(model_coeff)
  model_coeff_prefix <- case_when(model_coeff_sign == -1 ~ " - ",
                                  model_coeff_sign == 1 ~ " + ",
                                  model_coeff_sign == 0 ~ " + ")
  model_eqn <- paste(strsplit(as.character(model$call$formula), "~")[[2]], # 'y'
                     "=",
                     paste(if_else(model_coeff[1]<0, "- ", ""),
                           do.call(format, format_args)[1],
                           paste(model_coeff_prefix[-1],
                                 do.call(format, format_args)[-1],
                                 " * ",
                                 names(model_coeff[-1]),
                                 sep = "", collapse = ""),
                           sep = ""))
  return(model_eqn)
}


daggHeat <- df %>% filter(Person_Speed<3)%>%group_by(Scenario,FOD,Range,day)%>%summarize(avgSpeed=mean(Person_Speed),medianSpeed=median(Person_Speed),maxSpeed=max(Person_Speed),minSpeed=min(Person_Speed),objectDetected=sum(objDet,na.rm = TRUE),objectCollisions=sum(objColl,na.rm = TRUE),Time=max(Time_in_MS*1000))

###----------------Numeric Analysis part----------------###


dataWhole <- daggByScen %>%
  group_by(FOD, Range) %>%
  summarize(objectCollisions = mean(objectCollisions, na.rm = TRUE), objectDetected = mean(objectDetected, na.rm = TRUE), Time = mean(Time * 1000))

test<-daggByScen %>%
  group_by(FOD, Range) %>%
  summarize(objectCollisions = mean(objectCollisions, na.rm = TRUE), objectDetected = mean(objectDetected, na.rm = TRUE), Time = mean(Time * 1000))


#WOBBL removes the baseline from the data and leaves us with Whole-room and Corridor
daggByScenWOBL<-daggByScen[!daggByScen$FOD=="Baseline",]
m<-lm(Time~FOD*Range+totalTimeTraining,data=daggByScen[!daggByScen$FOD=="Baseline",])
summary(m)
model_equation(m)
daggByScenWOBL$predTime<-predict(m)

m0<-lm(log(Time)~log(totalTimeTraining)+FOD*log(Range),data=daggByScen)


baseDat <- daggByScen[daggByScen$FOD=="Baseline",]
mbaseDat <- lm(log(Time)~log(totalTimeTraining),data=baseDat)


wrDat <- daggByScen[daggByScen$FOD=="WholeRoom",]
mwrDat<- lm(log(Time)~log(totalTimeTraining),data=wrDat)
wr2Dat <- wrDat[wrDat$Range=="2",]
wr3Dat <- wrDat[wrDat$Range=="3",]
wr4Dat <- wrDat[wrDat$Range=="4",]

corrDat <- daggByScen[daggByScen$FOD=="Corridor",]
mcorrDat<- lm(log(Time)~log(totalTimeTraining),data=corrDat)
corr2Dat <- corrDat[corrDat$Range=="2",]
corr3Dat <- corrDat[corrDat$Range=="3",]
corr4Dat <- corrDat[corrDat$Range=="4",]

###----------------Plots data----------------###
lower_ci <- function(mean, se, n, conf_level = 0.95){
  lower_ci <- mean - qt(1 - ((1 - conf_level) / 2), n - 1) * se
}
upper_ci <- function(mean, se, n, conf_level = 0.95){
  upper_ci <- mean + qt(1 - ((1 - conf_level) / 2), n - 1) * se
}

daggByDFR<-daggByScen %>%group_by(FOD,day,Range)%>%summarize(totalTimeTraining=max(totalTimeTraining),avgTime=mean(Time),ssd = sd(Time),count=n(),se = ssd / sqrt(count))%>%mutate(lower_ci=lower_ci(avgTime,se,count),upper_ci=upper_ci(avgTime,se,count))

#Learning curve
totalTimeTraining=1:6000
#Set to summary variables 
FOD = "Baseline"
Range="1"
b=21.45979
z= -0.06329
#This is the Time fed into dxf
Time<- b*totalTimeTraining^z
baseDatxf=as.data.frame(totalTimeTraining)
baseDatxf=cbind(baseDatxf,Time)
baseDatxf=cbind(baseDatxf,FOD)
baseDatxf=cbind(baseDatxf,Range)

FOD = "Corridor" 
Range="2"
b=31.32990
z=-0.10500
Time<- b*totalTimeTraining^z
corr2Datxf=as.data.frame(totalTimeTraining)
corr2Datxf=cbind(corr2Datxf,Time)
corr2Datxf=cbind(corr2Datxf,FOD)
corr2Datxf=cbind(corr2Datxf,Range)

Range="3"
b=54.72364
z=-0.17482
Time<- b*totalTimeTraining^z
corr3Datxf=as.data.frame(totalTimeTraining)
corr3Datxf=cbind(corr3Datxf,Time)
corr3Datxf=cbind(corr3Datxf,FOD)
corr3Datxf=cbind(corr3Datxf,Range)

Range="4"
b=9.81972
z=0.03528
Time<- b*totalTimeTraining^z
corr4Datxf=as.data.frame(totalTimeTraining)
corr4Datxf=cbind(corr4Datxf,Time)
corr4Datxf=cbind(corr4Datxf,FOD)
corr4Datxf=cbind(corr4Datxf,Range)


FOD = "WholeRoom"
Range="2"
b=37.2835	
z=-0.1273
Time<- b*totalTimeTraining^z
wr2Datxf=as.data.frame(totalTimeTraining)
wr2Datxf=cbind(wr2Datxf,Time)
wr2Datxf=cbind(wr2Datxf,FOD)
wr2Datxf=cbind(wr2Datxf,Range)

Range="3"
b=47.50384	
z=-0.15325
Time<- b*totalTimeTraining^z
wr3Datxf=as.data.frame(totalTimeTraining)
wr3Datxf=cbind(wr3Datxf,Time)
wr3Datxf=cbind(wr3Datxf,FOD)
wr3Datxf=cbind(wr3Datxf,Range)

Range="4"
b=54.86090	
z=-0.16613
Time<- b*totalTimeTraining^z
wr4Datxf=as.data.frame(totalTimeTraining)
wr4Datxf=cbind(wr4Datxf,Time)
wr4Datxf=cbind(wr4Datxf,FOD)
wr4Datxf=cbind(wr4Datxf,Range)

knitr::opts_chunk$set(echo = TRUE)
```

## Data information
Below, a summary of our data is presented. In total, 420 tests were completed over three days (140 per day), using three different Field Of Detections (FOD - Baseline, WholeRoom and Corridor), with exception of WholeRoom and Corridor differing between three ranges (two, three and four meters), as Baseline represents the original wite cane. Scenarios describe the amount of different parkours the system was tested on (each condition with different lengths). In addition, each test logged the speed of the participant, the amount of objects detected by the cane, the amount of collisions by the user and the completion time of the individual parkours.
```{r first summary, echo=FALSE}

summary(daggByScen)

#kable(summary(daggByScen[1:16]), caption = "Data")
# summary(nameOfDataFile)
#Shows a table of the data (e.g. could be the coefficients for completion time to FOD compairson)
```


## Predicition of course completion time
The plot below shows the average time of completion of scenarios, over the course of the total time the user was training, using the system. Inspecting the x-axis, one can tell that the totalTimeTraining seems to differ between the FOD's. The cause is the order in which the different FOD's were tested over the three days, which ended up placing the Corridor in the middel of the dataset, leaving the Baseline and WholeRoom with more total training time on the final day.
<!--
Splitting the data up into different models for predection of completion time, the following coefficients were extracetd from each model.

Baseline data:
```{r baseData summary, echo=FALSE}
coef(lm(Time ~ totalTimeTraining, data = baseDat))
```

WholeRoom data
```{r wrData summary, echo=FALSE}
coef(lm(Time ~ totalTimeTraining, data = wrDat))
```

Corrdiro data
```{r corrData summary, echo=FALSE, message=FALSE}
coef(lm(Time ~ totalTimeTraining, data = corrDat))
```
-->

```{r Training time over scenario time, echo=FALSE, error=FALSE, message=FALSE, fig.height=10, fig.width=10}
#Figure has an error
traonOScenplot<-ggplot(daggByDFR,aes(x=totalTimeTraining,y=avgTime,color=factor(Range),shape=factor(Range)))+
  geom_point()+ 
  geom_smooth(size=0)+ 
  geom_errorbar(aes(ymin=lower_ci, ymax=upper_ci))+
  stat_smooth(method = 'nls', formula = 'y~a*x^b', method.args = list(start= c(a = 1,b=1)),se=FALSE)+
  theme_bw()+
  facet_grid(cols=vars(FOD))

suppressWarnings(print(traonOScenplot))
```


Bacause our predicitons were that FOD Corridor would perform better than FOD WholeRoom over time, we calculated coefficients for predicting the avgTime over totalTimeTraining, by sorting the aggregated data by FOD and Range - hence the following paramters for estimations were made:
**Note: FOD Corridor with a range of 4 meters gives the impression of getting worse over time, which is due to some immediate well achived run on the first day. In addition, the data contains some outliers which will need further investigation.**

###### Baseline data
```{r BaseData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = baseDat))
```

###### Corridor 2 meters data
```{r Corridor2mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = corr2Dat))
```

###### Corridor 3 meters data
```{r Corridor3mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = corr3Dat))
```

###### Corridor 4 meters data
```{r Corridor4mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = corr4Dat))
```

###### WholeRoom 2 meters data
```{r WholeRoom2mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = wr2Dat))

```

###### WholeRoom 3 meters data
```{r WholeRoom3mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = wr3Dat))
```

###### WholeRoom 4 meters data
```{r WholeRoom4mData summary, echo=FALSE, error=FALSE}
summary(nls(Time ~ b*totalTimeTraining^z,
            start = list(b = 1, z = 1),
            data = wr4Dat))
```


Feeding these estimation standars into the same formula used to gather the coefficients: $b*totalTimeTraining^z$ and pairing them with an interval of $1:6000$, we were able ot create curves predicting each FOD with their respective Range's improvement over time.
Plotting these new predictions onto the data, we see that FOD WholeRoom "recieves" a penalty as the Range increases, indicating, looking further ahead means slower completion time. Another aspect is that FOD Corridor seems to be at best with a Range of three meters, and also outperform FOD WholeRoom over training time

```{r Training time over scenario stretched ,echo=FALSE, error=FALSE, message=FALSE, fig.height=10, fig.width=10}
ggplot(daggByScen, aes(x=totalTimeTraining, y=Time, colour=factor(Range)))+
  geom_point()+ theme_bw()+
  geom_line(data=baseDatxf)+
  geom_line(data=corr2Datxf)+
  geom_line(data=corr3Datxf)+
  geom_line(data=corr4Datxf)+
  geom_line(data=wr2Datxf)+
  geom_line(data=wr3Datxf)+
  geom_line(data=wr4Datxf)+
    facet_grid(cols=vars(FOD))+
    ylim(0,30)

```



To further inspect the time used for completing each scenario, the following heatmap shows average completion time per scenario for the different FOD's with different ranges. Here the outliers stand out, in terms of scenario 19 in FOD Corridor day one and scenario five in DOF Baseline day two. Noteworthy is also day one of FOD WholeRoom, which is slower, compared to the other FOD's.

```{r TimePerScenarioHM, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=10}
ggplot(daggByScen, aes(x = Range, y = Scenario)) + 
  geom_tile(aes(fill = Time)) + 
  geom_text(aes(fill = daggByScen$Time, label = round(daggByScen$Time, 2))) + 
  scale_fill_gradient2(low = muted("red"), 
                       mid = "yellow", 
                       high = muted("green"), 
                       midpoint = 0.75) + 
  theme(panel.grid.major.x=element_blank(), 
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill="white"), 
        axis.text.x = element_text(angle=0, hjust = 1,vjust=1,size = 12,face = "bold"),
        plot.title = element_text(size=16,face="bold"),
        axis.text.y = element_text(size = 12,face = "bold")) + 
  ggtitle("HeatMap Over Time per Scenario") + 
  theme(legend.title=element_text(face="bold", size=10)) + 
  scale_y_continuous(trans = "reverse")+
  labs(fill="Time in s") +
  facet_grid(cols=vars(FOD), row=vars(day))
```




## Collisions and Detections


FOD w. Range | Detections | Collisions |
-------------|------------|------------|
Baseline     |    7.26    |    1.47    |
Corridor R2  |    7.01    |    1.05    |
Corridor R3  |    7.95    |    1.1     |
Corridor R4  |    7.52    |    1.25    |
WholeRoom R2 |     9      |    0.93    |
WholeRoom R3 |   12.53    |    1.03    |
WholeRoom R4 |   12.78    |    1.03    |



The heatmap below shows the amount of object collisions for each scenario, between differnt FOD's and Ranges. Noteworthy that using DOF WholeRoom, the participant managed to achieve collisions on scenario one, day one, which is supposed to be a clear walkingpath with objects spread out to the sides, making it difficult to collide with an object. A potential outlier also seems to be located in DOF Corridor day two scenario 20, however, further investigation would need to be conducted.
```{r, HmCollprScen, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=10}
ggplot(daggHeat, aes(x = Range, y = Scenario)) + 
  geom_tile(aes(fill = objectCollisions)) + 
  geom_text(aes(fill = daggHeat$objectCollisions, label = round(daggHeat$objectCollisions, 2))) + 
  scale_fill_gradient2(low = muted("green"), 
                       mid = "yellow", 
                       high = muted("red"), 
                       midpoint = 4) + 
  theme(panel.grid.major.x=element_blank(), 
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill="white"), 
        axis.text.x = element_text(angle=0, hjust = 1,vjust=1,size = 12,face = "bold"),
        plot.title = element_text(size=16,face="bold"),
        axis.text.y = element_text(size = 12,face = "bold")) + 
  ggtitle("HeatMap - Collisions per Scenario") + 
  theme(legend.title=element_text(face="bold", size=10)) + 
  scale_y_continuous(trans = "reverse")+
  labs(fill="Collisions") +
  facet_grid(cols=vars(FOD), row=vars(day))
```


Another heatmap shows the amount of object detections for each scenario, between differnt FOD's and Ranges. Again, scenario one is very noteworthy for the few detections using FOD Baseline and Corridor, where the walking path is clear, compared to FOD Wholeroom, which conducts alot of information.
```{r, HmDetprScen, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=10}
ggplot(daggHeat, aes(x = Range, y = Scenario)) + 
  geom_tile(aes(fill = objectDetected)) + 
  geom_text(aes(fill = daggHeat$objectDetected, label = round(daggHeat$objectDetected, 2))) + 
  scale_fill_gradient2(low = muted("green"), 
                       mid = "yellow", 
                       high = muted("red"), 
                       midpoint = 30) + 
  theme(panel.grid.major.x=element_blank(), 
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill="white"), 
        axis.text.x = element_text(angle=0, hjust = 1,vjust=1,size = 12,face = "bold"),
        plot.title = element_text(size=16,face="bold"),
        axis.text.y = element_text(size = 12,face = "bold")) + 
  ggtitle("HeatMap - Detections per Scenario") + 
  theme(legend.title=element_text(face="bold", size=10)) + 
  scale_y_continuous(trans = "reverse")+
  labs(fill="Detections") +
  facet_grid(cols=vars(FOD), row=vars(day))
```



Collisions and detections also have an impact on the speed the participant moves through scenarios with. Below two graphs show that the impact of collisions as well as detections both grow while speed decreases.


```{r Collisions/DetectionsprScenario ,echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=5}
ggplot(daggByScen,aes(y = avgSpeed, x = objectCollisions, color = factor(Range)))+
  geom_point(aes(alpha=.1))+ 
  geom_jitter()+
  #geom_smooth(size=0)+
  stat_smooth(method = 'nls', formula = 'y~a+x*b', method.args = list(start= c(a = 1,b=1)),se=FALSE)+
  theme_bw()+
  facet_grid(cols=vars(FOD))

ggplot(daggByScen,aes(y = avgSpeed, x = objectDetected, color = factor(Range)))+
  geom_point(aes(alpha=.1))+
  geom_jitter()+
  #geom_smooth(size=0)+
  stat_smooth(method = 'nls', formula = 'y~a+x*b', method.args = list(start= c(a = 1,b=1)),se=FALSE)+
  theme_bw()+
  facet_grid(cols=vars(FOD))
```






## Speed


Noteworthy, compared to the time it takes to complete a scenario over training time (as presented earlier), DOF Corridor with a Range of three meters becomes the fastest of the FOD Corridor Ranges on day three. However, looking at the average speed (as shown in the plot below), the corridor with a Range of two meters has a faster walking speed. This yields that a faster walking speed does not necessary mean a faster completion time.
```{r ,}
ggplot(daggByScen,aes(x=totalTimeTraining,y=avgSpeed,color=factor(Range)))+
  geom_point(aes(alpha=.1))+ 
  stat_smooth(method = 'nls', formula = 'y~a*x^b', method.args = list(start= c(a = 1,b=1)),se=FALSE)+
  facet_grid(cols=vars(FOD))
```


```{r HmAvgspdScen, echo=FALSE, message=FALSE, warning=FALSE, fig.height=10, fig.width=10}
ggplot(daggHeat, aes(x = Range, y = Scenario)) + 
  geom_tile(aes(fill = avgSpeed)) + 
  geom_text(aes(fill = daggHeat$avgSpeed, label = round(daggHeat$avgSpeed, 2))) + 
  scale_fill_gradient2(low = muted("red"), 
                       mid = "yellow", 
                       high = muted("green"), 
                       midpoint = 0.75) + 
  theme(panel.grid.major.x=element_blank(), 
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill="white"), 
        axis.text.x = element_text(angle=0, hjust = 1,vjust=1,size = 12,face = "bold"),
        plot.title = element_text(size=16,face="bold"),
        axis.text.y = element_text(size = 12,face = "bold")) + 
  ggtitle("HeatMap - avgSpeed per Scenario") + 
  theme(legend.title=element_text(face="bold", size=10)) + 
  scale_y_continuous(trans = "reverse")+
  labs(fill="avgSpeed") +
  facet_grid(cols=vars(FOD), row=vars(day))
```


## Analysis reflection



##Analysis conclusion